{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "xVrnvbKaqkiW",
      "metadata": {
        "id": "xVrnvbKaqkiW"
      },
      "outputs": [],
      "source": [
        "# Math125 Final Project\n",
        "\n",
        "\n",
        "\n",
        "# by Xianmai(Chris) Liang and James Ma\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cc1a5c61",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cc1a5c61",
        "outputId": "e61db82e-0225-424e-9cbe-bf5187c6b8bf"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-2-a779fb4e0174>:11: FutureWarning: Passing a negative integer is deprecated in version 1.0 and will not be supported in future version. Instead, use None to not limit the column width.\n",
            "  pd.set_option('display.max_colwidth', -1)\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from numpy import linalg as LA\n",
        "import string\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.preprocessing import normalize\n",
        "from sklearn.metrics.pairwise import euclidean_distances\n",
        "pd.set_option('display.max_rows', 500)\n",
        "pd.set_option('display.max_columns', 500)\n",
        "pd.set_option('display.width', 1000)\n",
        "pd.set_option('display.max_colwidth', -1)\n",
        "import csv\n",
        "import os\n",
        "import sklearn.metrics.pairwise as pdist\n",
        "from sklearn.metrics.pairwise import euclidean_distances\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2cc1a920",
      "metadata": {
        "id": "2cc1a920"
      },
      "outputs": [],
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import make_pipeline\n",
        "\n",
        "from heapq import heapify, heappush, heappop\n",
        "\n",
        "import numpy as np\n",
        "from numpy import array\n",
        "import scipy.sparse as sp\n",
        "from sklearn.preprocessing import normalize\n",
        "from scipy.sparse import diags\n",
        "from scipy.sparse import csr_matrix\n",
        "\n",
        "import time\n",
        "t_s = time.time()\n",
        "\n",
        "import sklearn.metrics.pairwise as pdist\n",
        "from sklearn.metrics.pairwise import euclidean_distances\n",
        "import gc\n",
        "\n",
        "gc.collect()\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "90c98b9b",
      "metadata": {
        "id": "90c98b9b"
      },
      "outputs": [],
      "source": [
        "def getLabDic(lables):\n",
        "    \"\"\"input a list of lables\n",
        "    return a dictionary mapping labels to 0,1,2,3...n-1\n",
        "    \"\"\"\n",
        "    Labs=list(set(lables))\n",
        "    print(Labs)\n",
        "    n=len(Labs)\n",
        "    labdic={}\n",
        "    for i in range(n):\n",
        "        labdic[Labs[i]]=i\n",
        "    for k,v in labdic.items():\n",
        "        print(str(k)+\"--->\"+str(v))\n",
        "    return labdic\n",
        "\n",
        "def getdatafromFile(filenm):\n",
        "    \"\"\" this function uses the input filename\n",
        "      assume each line: label +\\t+ line\n",
        "      return list of labels, list of lines\n",
        "    \"\"\"\n",
        "    dat=[]\n",
        "    Y=[]\n",
        "    openf=open(filenm, 'r', encoding=\"latin1\")\n",
        "    for i, ln in enumerate(openf):\n",
        "        ln2=ln.split('\\t')\n",
        "        Y.append(ln2[0])\n",
        "        dat.append(ln2[1])\n",
        "    openf.close()\n",
        "    return (dat,Y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dd7f78fe",
      "metadata": {
        "id": "dd7f78fe"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dab44d82",
      "metadata": {
        "id": "dab44d82"
      },
      "outputs": [],
      "source": [
        "test_r8fn='r8-test-all-terms.txt'\n",
        "train_r8fn='r8-train-all-terms.txt'\n",
        "test_20ngfn='20ng-test-all-terms.txt'\n",
        "train_20ngfn='20ng-train-all-terms.txt'\n",
        "# train_ohfn='train_ohsumed_by_line.txt'\n",
        "# test_ohfn='test_ohsumed_by_line.txt'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "98d704af",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "98d704af",
        "outputId": "cfb96c13-d3f0-4198-a2aa-8a7c23593737"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['crude', 'interest', 'trade', 'acq', 'grain', 'money-fx', 'ship', 'earn']\n",
            "crude--->0\n",
            "interest--->1\n",
            "trade--->2\n",
            "acq--->3\n",
            "grain--->4\n",
            "money-fx--->5\n",
            "ship--->6\n",
            "earn--->7\n"
          ]
        }
      ],
      "source": [
        "(traindat,trainY)=getdatafromFile(train_r8fn)\n",
        "(testdat, testY)=getdatafromFile(test_r8fn)\n",
        "r8Labdic=getLabDic(trainY)\n",
        "train_lab=[r8Labdic[e] for e in trainY]\n",
        "test_lab=[r8Labdic[e] for e in testY]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9fbbcf69",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9fbbcf69",
        "outputId": "bb899e69-d97b-447b-84b2-2f67554066a9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5485\n",
            "2189\n"
          ]
        }
      ],
      "source": [
        "print(len(train_lab))\n",
        "print(len(test_lab))\n",
        "train_lab=np.asarray(train_lab)\n",
        "test_lab=np.asarray(test_lab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e5e5006d",
      "metadata": {
        "id": "e5e5006d"
      },
      "outputs": [],
      "source": [
        "r8LabdicRev={}\n",
        "for k,v in r8Labdic.items():\n",
        "    r8LabdicRev[v]=k"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7338a76b",
      "metadata": {
        "id": "7338a76b"
      },
      "outputs": [],
      "source": [
        "docs=['I like Brandeis', 'machine learning', 'I work at Brandeis','machine learning is awesome']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f25f0647",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f25f0647",
        "outputId": "a8d7795b-4c01-41b4-e108-4afa6709f305"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "there are 4 docs.\n",
            "(4, 8)\n",
            "length of vocab=8\n"
          ]
        }
      ],
      "source": [
        "vect = CountVectorizer(ngram_range=(1,1), stop_words=None)\n",
        "N=len(docs)\n",
        "print(f\"there are { N } docs.\")\n",
        "tfx=vect.fit_transform(docs)\n",
        "print(tfx.shape)\n",
        "vocabs=vect.get_feature_names_out()\n",
        "print(f\"length of vocab={len(vocabs)}\")\n",
        "dfs=csr_matrix(((tfx>0)*1).sum(axis=0)).toarray()[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "997b0366",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "997b0366",
        "outputId": "3ad86feb-241f-4556-999d-64043a3b2448"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([1, 1, 2, 1, 2, 1, 2, 1])"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dfs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2eb3bb77",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2eb3bb77",
        "outputId": "668ac20a-dac9-4fe1-9692-325d1d549846"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array(['at', 'awesome', 'brandeis', 'is', 'learning', 'like', 'machine',\n",
              "       'work'], dtype=object)"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vocabs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f89aee4b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f89aee4b",
        "outputId": "e6ac83fc-e377-4bbf-e943-a52dff1704b6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0, 0, 1, 0, 0, 1, 0, 0],\n",
              "       [0, 0, 0, 0, 1, 0, 1, 0],\n",
              "       [1, 0, 1, 0, 0, 0, 0, 1],\n",
              "       [0, 1, 0, 1, 1, 0, 1, 0]])"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tfx.toarray()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "afcd3522",
      "metadata": {
        "id": "afcd3522"
      },
      "outputs": [],
      "source": [
        "tfx2=normalize(tfx, norm='l1',axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1887fd82",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1887fd82",
        "outputId": "c04cf5a0-cfc3-4091-8c3a-1c0ae9921b06"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0.        , 0.        , 0.5       , 0.        , 0.        ,\n",
              "        0.5       , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.5       ,\n",
              "        0.        , 0.5       , 0.        ],\n",
              "       [0.33333333, 0.        , 0.33333333, 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.33333333],\n",
              "       [0.        , 0.25      , 0.        , 0.25      , 0.25      ,\n",
              "        0.        , 0.25      , 0.        ]])"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tfx2.toarray()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b229dc74",
      "metadata": {
        "id": "b229dc74"
      },
      "outputs": [],
      "source": [
        "dfs=csr_matrix(((tfx>0)*1).sum(axis=0)).toarray()[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1cfee121",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1cfee121",
        "outputId": "7b67f5db-4c61-4a24-b642-5a642c5d9ba0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([1, 1, 2, 1, 2, 1, 2, 1])"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dfs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ce8360c4",
      "metadata": {
        "id": "ce8360c4"
      },
      "outputs": [],
      "source": [
        "def tfidf(traindocs, stopwordlist=None):\n",
        "    vect = CountVectorizer(ngram_range=(1,1), stop_words=stopwordlist)\n",
        "    N=len(traindocs)\n",
        "    # print(f\"there are { N } docs.\")\n",
        "    tfx=vect.fit_transform(traindocs)\n",
        "    # print(tfx.shape)\n",
        "    vocabs=vect.get_feature_names_out()\n",
        "    # print(f\"length of vocab={len(vocabs)}\")\n",
        "    dfs=csr_matrix(((tfx>0)*1).sum(axis=0)).toarray()[0]\n",
        "    # print(\"shape of dfs:\"+str(dfs.shape))\n",
        "    # print(\"len of dfs: \"+str(len(dfs)))\n",
        "\n",
        "    vocabs=vect.get_feature_names_out()\n",
        "    # print(f\"length of vocab={len(vocabs)}\")\n",
        "\n",
        "    tfx=normalize(tfx, norm='l1',axis=1)\n",
        "    # print(\"shape of tfx1: \"+str(tfx.shape))\n",
        "    # print(\"computing tfidf ... \")\n",
        "    idfs=[1+np.log(N/(1+d)) for d in dfs]\n",
        "    idfs_diag=diags(idfs)\n",
        "    tfidf=tfx.dot(idfs_diag)\n",
        "    return tfidf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ee8c0e24",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ee8c0e24",
        "outputId": "a16fa4bb-0d78-4bf8-b8c7-2670a1e85cfa"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<5485x19956 sparse matrix of type '<class 'numpy.float64'>'\n",
              "\twith 320397 stored elements in Compressed Sparse Row format>"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tfidf(traindat)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "58b9b8f9",
      "metadata": {
        "id": "58b9b8f9"
      },
      "outputs": [],
      "source": [
        "def evaluate(testdocs, testlabs):\n",
        "    predictionlabs=predict(testdocs)\n",
        "    #prediction=np.asarray(prediction)\n",
        "    count=0; ntest=len(predictionlabs)\n",
        "    for i in range(ntest):\n",
        "        if predictionlabs[i]==testlabs[i]:\n",
        "            count=count+1\n",
        "    test_error = 1 - count/ntest\n",
        "    return test_error\n",
        "\n",
        "\n",
        "def KNNpredict(neighbor_classes, C, cross_val=False):\n",
        "    # Make sure all classes are considered\n",
        "    labels = np.concatenate((neighbor_classes, list(range(C))))\n",
        "    # Find class frequency among neighbors\n",
        "    weights = np.unique(labels, return_counts=True)[1]\n",
        "    # Find most popular class\n",
        "    prediction = np.argmax(weights)\n",
        "    nn=len(neighbor_classes)\n",
        "    # If most popular class is ambiguous try with fewer neighbors; else return\n",
        "    if sum(weights[prediction] == weights) > 1 and nn>2:\n",
        "        return KNNpredict(neighbor_classes[:-2], C)\n",
        "    else:\n",
        "        return prediction\n",
        "\n",
        "\n",
        "\n",
        "def knnClassify(y_train, dist, n_neighbors=7):\n",
        "    ## y_train: training docs labels; dist: testdocs vs traindocs pairwise distance matrix\n",
        "    # Number of all different classes\n",
        "    #n_classes = len(np.unique(y_train))\n",
        "    prediction = []\n",
        "    ntestsample=dist.shape[0]\n",
        "    for i in range(ntestsample):\n",
        "        doc_to_train=dist[i,:]\n",
        "        # Find indices of n_neighbors closest documents\n",
        "        rank = np.argsort(doc_to_train)[:n_neighbors]\n",
        "        # Make prediction based on most popular class among neighbors\n",
        "        prediction.append(KNNpredict(y_train[rank], n_classes))\n",
        "    return prediction\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "id": "uTV_2W6xdefb",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uTV_2W6xdefb",
        "outputId": "060168d8-5886-468d-a7df-7d63da3086a7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.9488350845134764\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.99      0.94       696\n",
            "           1       0.84      0.64      0.73        87\n",
            "           2       0.98      0.89      0.94       121\n",
            "           3       1.00      0.50      0.67        10\n",
            "           4       0.92      0.93      0.93        75\n",
            "           5       0.95      0.74      0.83        81\n",
            "           6       0.99      0.99      0.99      1083\n",
            "           7       1.00      0.56      0.71        36\n",
            "\n",
            "    accuracy                           0.95      2189\n",
            "   macro avg       0.95      0.78      0.84      2189\n",
            "weighted avg       0.95      0.95      0.95      2189\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# logistic regression\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "vect = TfidfVectorizer(ngram_range=(1, 1), stop_words=None)\n",
        "X_train_tfidf = vect.fit_transform(traindat)\n",
        "\n",
        "X_test_tfidf = vect.transform(testdat)\n",
        "\n",
        "lr_model = LogisticRegression()\n",
        "lr_model.fit(X_train_tfidf, train_lab)\n",
        "\n",
        "test_predictions = lr_model.predict(X_test_tfidf)\n",
        "print(\"Accuracy:\", accuracy_score(test_lab, test_predictions))\n",
        "print(classification_report(test_lab, test_predictions))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "QdC-GU2agxw7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QdC-GU2agxw7",
        "outputId": "c51ee5f7-df62-4a34-cefb-954c0e58a449"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.8835084513476473\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.75      0.85       696\n",
            "           1       0.80      0.90      0.84        87\n",
            "           2       0.90      0.92      0.91       121\n",
            "           3       0.88      0.70      0.78        10\n",
            "           4       0.70      0.97      0.81        75\n",
            "           5       0.82      0.73      0.77        81\n",
            "           6       0.87      0.98      0.92      1083\n",
            "           7       0.85      0.61      0.71        36\n",
            "\n",
            "    accuracy                           0.88      2189\n",
            "   macro avg       0.85      0.82      0.82      2189\n",
            "weighted avg       0.89      0.88      0.88      2189\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# KNN\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "knn_model = KNeighborsClassifier(n_neighbors=5)\n",
        "\n",
        "knn_model.fit(X_train_tfidf, train_lab)\n",
        "\n",
        "test_predictions = knn_model.predict(X_test_tfidf)\n",
        "print(\"Accuracy:\", accuracy_score(test_lab, test_predictions))\n",
        "print(classification_report(test_lab, test_predictions))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "id": "P8Icmr0aiGnd",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P8Icmr0aiGnd",
        "outputId": "87e57fb2-8514-4aeb-cc3f-8922a8526401"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.9168570123343993\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.98      0.90       696\n",
            "           1       0.76      0.47      0.58        87\n",
            "           2       1.00      0.74      0.85       121\n",
            "           3       1.00      0.40      0.57        10\n",
            "           4       0.84      0.85      0.85        75\n",
            "           5       0.96      0.60      0.74        81\n",
            "           6       0.98      0.99      0.99      1083\n",
            "           7       1.00      0.17      0.29        36\n",
            "\n",
            "    accuracy                           0.92      2189\n",
            "   macro avg       0.92      0.65      0.72      2189\n",
            "weighted avg       0.92      0.92      0.91      2189\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Random forest\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "rf_model = RandomForestClassifier()\n",
        "\n",
        "rf_model.fit(X_train_tfidf, train_lab)\n",
        "\n",
        "\n",
        "test_predictions = rf_model.predict(X_test_tfidf)\n",
        "print(\"Accuracy:\", accuracy_score(test_lab, test_predictions))\n",
        "print(classification_report(test_lab, test_predictions))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "id": "V6uC_N57iR6P",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V6uC_N57iR6P",
        "outputId": "2f27b20f-3093-49b0-be8b-697619016c45"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.9470077661032434\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.99      0.94       696\n",
            "           1       0.86      0.63      0.73        87\n",
            "           2       0.99      0.88      0.93       121\n",
            "           3       1.00      0.60      0.75        10\n",
            "           4       0.93      0.92      0.93        75\n",
            "           5       0.94      0.77      0.84        81\n",
            "           6       0.99      0.99      0.99      1083\n",
            "           7       1.00      0.44      0.62        36\n",
            "\n",
            "    accuracy                           0.95      2189\n",
            "   macro avg       0.95      0.78      0.84      2189\n",
            "weighted avg       0.95      0.95      0.94      2189\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# SVM\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "svm_model = SVC()\n",
        "\n",
        "svm_model.fit(X_train_tfidf, train_lab)\n",
        "\n",
        "test_predictions = svm_model.predict(X_test_tfidf)\n",
        "print(\"Accuracy:\", accuracy_score(test_lab, test_predictions))\n",
        "print(classification_report(test_lab, test_predictions))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "id": "oE9vly9Ji8EH",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oE9vly9Ji8EH",
        "outputId": "60c76793-0e20-4a82-d6f7-c3de0e3bc732"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.8195523069894929\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.72      0.96      0.83       696\n",
            "           1       0.80      0.05      0.09        87\n",
            "           2       0.97      0.31      0.47       121\n",
            "           3       0.00      0.00      0.00        10\n",
            "           4       1.00      0.12      0.21        75\n",
            "           5       1.00      0.06      0.12        81\n",
            "           6       0.89      0.99      0.93      1083\n",
            "           7       0.00      0.00      0.00        36\n",
            "\n",
            "    accuracy                           0.82      2189\n",
            "   macro avg       0.67      0.31      0.33      2189\n",
            "weighted avg       0.83      0.82      0.77      2189\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "# Naive Bayes\n",
        "\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "nb_model = MultinomialNB()\n",
        "\n",
        "nb_model.fit(X_train_tfidf, train_lab)\n",
        "\n",
        "test_predictions = nb_model.predict(X_test_tfidf)\n",
        "print(\"Accuracy:\", accuracy_score(test_lab, test_predictions))\n",
        "print(classification_report(test_lab, test_predictions))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 119,
      "id": "AFXZLC6fj3nN",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AFXZLC6fj3nN",
        "outputId": "3b76186d-e5e1-4352-e23f-b8bc34eae088"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.8835084513476473\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.91      0.85       696\n",
            "           1       0.67      0.25      0.37        87\n",
            "           2       0.88      0.89      0.89       121\n",
            "           3       1.00      0.30      0.46        10\n",
            "           4       0.92      0.80      0.86        75\n",
            "           5       0.81      0.62      0.70        81\n",
            "           6       0.95      0.96      0.96      1083\n",
            "           7       1.00      0.33      0.50        36\n",
            "\n",
            "    accuracy                           0.88      2189\n",
            "   macro avg       0.88      0.63      0.70      2189\n",
            "weighted avg       0.88      0.88      0.87      2189\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Decision tree\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "dt_model = DecisionTreeClassifier(max_depth=10)\n",
        "\n",
        "dt_model.fit(X_train_tfidf, train_lab)\n",
        "\n",
        "test_predictions = dt_model.predict(X_test_tfidf)\n",
        "print(\"Accuracy:\", accuracy_score(test_lab, test_predictions))\n",
        "print(classification_report(test_lab, test_predictions))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 121,
      "id": "qE0Rn5FNlIhp",
      "metadata": {
        "id": "qE0Rn5FNlIhp"
      },
      "outputs": [],
      "source": [
        "# tried to implement LSTM but really bad accuracy \n",
        "\n",
        "# pip install tensorflow\n",
        "# import tensorflow as tf\n",
        "# from tensorflow.keras.models import Sequential\n",
        "# from tensorflow.keras.layers import LSTM, Dense, Embedding, Dropout\n",
        "# from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "# from tensorflow.keras.preprocessing.sequence import pad_sequences\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 122,
      "id": "ULJiCX5ClLik",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ULJiCX5ClLik",
        "outputId": "7a05103e-3476-44b4-d9f2-a84a9ccf1e19"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "172/172 [==============================] - 64s 309ms/step - loss: -58.3485 - accuracy: 0.0379\n",
            "Epoch 2/5\n",
            "172/172 [==============================] - 58s 337ms/step - loss: -123.8005 - accuracy: 0.0376\n",
            "Epoch 3/5\n",
            "172/172 [==============================] - 48s 277ms/step - loss: -183.0952 - accuracy: 0.0376\n",
            "Epoch 4/5\n",
            "172/172 [==============================] - 47s 271ms/step - loss: -242.8777 - accuracy: 0.0376\n",
            "Epoch 5/5\n",
            "172/172 [==============================] - 47s 276ms/step - loss: -302.8162 - accuracy: 0.0376\n",
            "69/69 [==============================] - 4s 38ms/step - loss: -310.8559 - accuracy: 0.0397\n",
            "Test Accuracy: 0.03974417597055435\n"
          ]
        }
      ],
      "source": [
        "# tokenizer = Tokenizer(num_words=5000)\n",
        "# tokenizer.fit_on_texts(traindat)\n",
        "\n",
        "# X_train_seq = tokenizer.texts_to_sequences(traindat)\n",
        "# X_test_seq = tokenizer.texts_to_sequences(testdat)\n",
        "\n",
        "# max_seq_length = 100\n",
        "# X_train = pad_sequences(X_train_seq, maxlen=max_seq_length)\n",
        "# X_test = pad_sequences(X_test_seq, maxlen=max_seq_length)\n",
        "\n",
        "# model = Sequential()\n",
        "# model.add(Embedding(input_dim=5000, output_dim=128, input_length=max_seq_length))\n",
        "# model.add(LSTM(128, dropout=0.2, recurrent_dropout=0.2))\n",
        "# model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# model.fit(X_train, train_lab, batch_size=32, epochs=5)\n",
        "# loss, accuracy = model.evaluate(X_test, test_lab)\n",
        "# print(\"Test Accuracy:\", accuracy)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 123,
      "id": "CnBIxS4zm5KT",
      "metadata": {
        "id": "CnBIxS4zm5KT"
      },
      "outputs": [],
      "source": [
        "#Same for RNN\n",
        "\n",
        "# import tensorflow as tf\n",
        "# from tensorflow.keras.models import Sequential\n",
        "# from tensorflow.keras.layers import SimpleRNN, Embedding, Dense, Dropout\n",
        "# from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "# from tensorflow.keras.preprocessing.sequence import pad_sequences\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 124,
      "id": "YsqR4Zvjm8LT",
      "metadata": {
        "id": "YsqR4Zvjm8LT"
      },
      "outputs": [],
      "source": [
        "# tokenizer = Tokenizer(num_words=5000)\n",
        "# tokenizer.fit_on_texts(traindat)\n",
        "\n",
        "# X_train_seq = tokenizer.texts_to_sequences(traindat)\n",
        "# X_test_seq = tokenizer.texts_to_sequences(testdat)\n",
        "\n",
        "# max_seq_length = 100  # Define the max sequence length\n",
        "# X_train = pad_sequences(X_train_seq, maxlen=max_seq_length)\n",
        "# X_test = pad_sequences(X_test_seq, maxlen=max_seq_length)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 125,
      "id": "wpGWPCcbm-Ij",
      "metadata": {
        "id": "wpGWPCcbm-Ij"
      },
      "outputs": [],
      "source": [
        "# model = Sequential()\n",
        "# model.add(Embedding(input_dim=5000, output_dim=128, input_length=max_seq_length))\n",
        "# model.add(SimpleRNN(128, dropout=0.2, recurrent_dropout=0.2))\n",
        "# model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 126,
      "id": "uRYwxighnAEP",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uRYwxighnAEP",
        "outputId": "87c694e3-4a0f-47b4-9abb-507185dd1cb6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "172/172 [==============================] - 14s 67ms/step - loss: -49.7079 - accuracy: 0.0423\n",
            "Epoch 2/5\n",
            "172/172 [==============================] - 11s 66ms/step - loss: -126.3939 - accuracy: 0.0376\n",
            "Epoch 3/5\n",
            "172/172 [==============================] - 11s 61ms/step - loss: -190.8492 - accuracy: 0.0379\n",
            "Epoch 4/5\n",
            "172/172 [==============================] - 11s 64ms/step - loss: -253.1404 - accuracy: 0.0385\n",
            "Epoch 5/5\n",
            "172/172 [==============================] - 11s 66ms/step - loss: -314.5240 - accuracy: 0.0390\n",
            "69/69 [==============================] - 1s 11ms/step - loss: -322.3336 - accuracy: 0.0411\n",
            "Test Accuracy: 0.04111466556787491\n"
          ]
        }
      ],
      "source": [
        "# model.fit(X_train, train_lab, batch_size=32, epochs=5)\n",
        "# loss, accuracy = model.evaluate(X_test, test_lab)\n",
        "# print(\"Test Accuracy:\", accuracy)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
